{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近完成了sqe2seq聊天模型，磕磕碰碰的遇到不少问题，最终总算是做出来了，并符合自己的预期结果。\n",
    "\n",
    "## 本文目的\n",
    "利用流程图，从理论方面，回顾，总结seq2seq模型,\n",
    "<br/>\n",
    "\n",
    "## seq2seq概念\n",
    "**你给模型一段输入，它返回一段输出！**\n",
    "\n",
    "**可以用在这些情景，聊天模型、翻译、看图说话、主旨提取等等涉及自然语言的层面，用途较广泛**\n",
    "\n",
    "例如：\n",
    "\n",
    "<font color=#FF7F00 >输入\"今天中午吃什么\",</font> \n",
    "<font color=#FF7F00 >输出\"吃兰州拉面\"。</font>\n",
    "\n",
    "\n",
    "**seq2seq是通过encoder编译器将一段输入，编译，汇聚成一个状态。再通过decoder解析器，解析该状态，返回一个输出！**\n",
    "\n",
    "encoder和decoder都是建立再LSTM或者RNN的基础上。\n",
    "\n",
    "\n",
    "<br/>\n",
    "## 运行流程\n",
    "\n",
    "### 1. 分词\n",
    "输入\"今天中午吃什么\"\n",
    "\n",
    "通过结巴分词工具，分词为[\"今天\", \"中午\", \"吃\", \"什么\"]\n",
    "\n",
    "输出结果为：输入通过seq2seq的计算后，输出结果为[\"吃\", \"拉州\", \"拉面\"]\n",
    "\n",
    "\n",
    "### 2. 分词向量化\n",
    "对于分词最终都会转换为相应的向量\n",
    "我采用了两种方法，将分词转换为向量\n",
    "1.随机定义分词的向量，训练过程中，不断的修改，最终形成分词向量。\n",
    "\n",
    "（下面代码，可以忽略）\n",
    "<font >\n",
    "    \n",
    "```\n",
    " self.dec_Wemb = tf.get_variable('embedding', \n",
    "                       initializer=tf.random_uniform([dec_vocab_size + 2, self.dec_emb_size]), \n",
    "                       dtype=tf.float32)\n",
    "\n",
    "```\n",
    "</font> \n",
    "\n",
    "2.使用gesim工具，将分词转换为向量。(我认为这个好，拓展性广很多)\n",
    "<font >\n",
    "    \n",
    "```\n",
    "for world in all_words_list:\n",
    "    # [\"_GAO_\", \"_PAD_\", \"*\",\n",
    "    if world == \"_GAO_\" or world == \"_PAD_\" or world == \"*\":\n",
    "        continue\n",
    "    try:\n",
    "        embedding.append(model[world].tolist())\n",
    "    except KeyError:\n",
    "        embedding.append([0.5] * vim)\n",
    "\n",
    "```\n",
    "\n",
    "</font> \n",
    "\n",
    "\n",
    "### 3.seq2seq核心运作如下流程图\n",
    "这里是基础模型(还有attention模型，schedule模型等)\n",
    "模型的核心点都是在encoder处，编译整理输入状态，传递给decoder解析器，解析得到结果！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./截图/seq2seq_basic.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jianshu.com/p/83443b2baf27\n",
    "    \n",
    "good_blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "使用这个模型进行seq2seq，通常不能得到好的结果。尤其是在句子较长的时候。\n",
    "为了得到好的结果，可以采用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
